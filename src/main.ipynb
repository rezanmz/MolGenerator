{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed400b2a-4f31-4565-ab0b-c638509a5d84",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bdf5477-9b95-4810-9ae0-511cf0d8ce03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import RGCNConv\n",
    "from torch_geometric.datasets import ZINC\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a655a77c-5ec7-4038-b7b7-cc185ded94c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RealNVP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d39c8-63c2-4cb3-b01a-7bfbcbf30c87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fully connected neural network for the base network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9787faeb-54e5-46bd-aa90-34c7c792f20f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf98c3-d87d-47ba-91e1-59b7c40ad976",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35c7c86-870e-4e9c-b555-a6c699d5a14f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim=8, base_network=FCNN):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.t1 = base_network(dim // 2, dim // 2, hidden_dim)\n",
    "        self.s1 = base_network(dim // 2, dim // 2, hidden_dim)\n",
    "        self.t2 = base_network(dim // 2, dim // 2, hidden_dim)\n",
    "        self.s2 = base_network(dim // 2, dim // 2, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lower, upper = x[:, :self.dim // 2], x[:, self.dim // 2:]\n",
    "        t1_transformed = self.t1(lower)\n",
    "        s1_transformed = self.s1(lower)\n",
    "        upper = t1_transformed + upper * torch.exp(s1_transformed)\n",
    "        t2_transformed = self.t2(upper)\n",
    "        s2_transformed = self.s2(upper)\n",
    "        lower = t2_transformed + lower * torch.exp(s2_transformed)\n",
    "        z = torch.cat([lower, upper], dim=1)\n",
    "        log_det = torch.sum(s1_transformed, dim=1) + torch.sum(s2_transformed, dim=1)\n",
    "        return z, log_det\n",
    "\n",
    "    def inverse(self, z):\n",
    "        lower, upper = z[:, :self.dim // 2], z[:, self.dim // 2:]\n",
    "        t2_transformed = self.t2(upper)\n",
    "        s2_transformed = self.s2(upper)\n",
    "        lower = (lower - t2_transformed) * torch.exp(-s2_transformed)\n",
    "        t1_transformed = self.t1(lower)\n",
    "        s1_transformed = self.s1(lower)\n",
    "        upper = (upper - t1_transformed) * torch.exp(-s1_transformed)\n",
    "        x = torch.cat([lower, upper], dim=1)\n",
    "        log_det = torch.sum(-s1_transformed, dim=1) + torch.sum(-s2_transformed, dim=1)\n",
    "        return x, log_det"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1414f2-d767-42e2-b5ad-b6ee8477a463",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68385a-929d-498b-8658-f43e11937922",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b74a3a69-f9f3-4fbc-9c5e-9f0dd6d818f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        num_nodes,\n",
    "        num_features, \n",
    "        num_edge_types,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.flow_model = RealNVP(input_dim)\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_features = num_features\n",
    "        self.num_edge_types = num_edge_types\n",
    "        \n",
    "        self.adj = nn.Linear(input_dim, num_nodes * num_nodes * (num_edge_types + 1))\n",
    "        self.feat = nn.Linear(input_dim, num_nodes * num_features)\n",
    "    def forward(self, x):\n",
    "        z, _ = self.flow_model(x)\n",
    "        # z = x\n",
    "        \n",
    "        adj = self.adj(z).view(x.shape[0], self.num_nodes, self.num_nodes, self.num_edge_types + 1)\n",
    "        adj = torch.nn.functional.softmax(adj, -1)\n",
    "        # adj[torch.where(adj == adj.max(-1))] == 1\n",
    "        # adj[torch.where(adj != adj.max(-1))] == 0\n",
    "        # adj[:, :, :, 0] = adj[:, :, :, 0] - 1\n",
    "        \n",
    "        feat = self.feat(z).view(x.shape[0], self.num_nodes, self.num_features)\n",
    "        feat = torch.nn.functional.softmax(feat, -1)\n",
    "        \n",
    "        \n",
    "        return adj, feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ead078-1f8f-4a2a-8d9d-c6ee03f8abc8",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c590704-3390-4f61-9d7b-3b6954781d5f",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "61342e50-8185-4d43-b1ce-2f31c778e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.rand(in_channels, out_channels, requires_grad=True))\n",
    "    def forward(self, A, X):\n",
    "        A_hat = A + torch.eye(A.size(1))\n",
    "        D = A_hat.sum(2).diag_embed()\n",
    "        D = D.inverse().sqrt()\n",
    "        A_hat = D.bmm(A_hat).bmm(D)\n",
    "        out = A_hat.bmm(X).matmul(self.W)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876bac4f-99a9-4690-bd77-6bb0733568c3",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "22fcf098-1146-4fbc-b461-a8e6b3a48201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_features, num_edge_types):\n",
    "        super().__init__()\n",
    "        # Use Relational GCN to support multiple edge types - same layer as MolGAN paper\n",
    "        # self.gcn = RGCNConv(num_features, 1, num_edge_types)\n",
    "        self.gcns = nn.ModuleList([\n",
    "            GCNConv(num_features, 1) for _ in range(num_edge_types)\n",
    "        ])\n",
    "        # self.gcns = nn.ModuleList([\n",
    "        #     nn.Linear(num_features, 1) for _ in range(num_edge_types)\n",
    "        # ])\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "    def forward(self, adj, x):\n",
    "        # x, edge_index, edge_type = data['x'], data['edge_index'], data['edge_type']\n",
    "        # out = self.gcn(x, edge_index, edge_type)\n",
    "        # out = self.gcns[0](adj[:, :, :, 1], x)\n",
    "        out = torch.zeros(adj.size(0), 1)\n",
    "        for edge_type, gcn in enumerate(self.gcns):\n",
    "            out += gcn(adj[:, :, :, edge_type], x).mean(1)\n",
    "            # out += gcn(x).mean(1)\n",
    "        return self.activation(out)\n",
    "        # return out.mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbf62a-b1e9-4e79-b916-48455ebfaeec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca701f47-6b98-48ad-8ca7-ad3b76f25dc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a41e64a-e351-4b62-94b0-d543eccca6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = ZINC('../dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e43aea0-60ad-4bd7-9d0f-fb977c8aafa3",
   "metadata": {},
   "source": [
    "### For now, filter molecules to have the same number of atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88bec322-0fcb-4831-b552-63fbe6b8d2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_nodes = {}\n",
    "for mol in dataset:\n",
    "    if mol.num_nodes not in num_nodes:\n",
    "        num_nodes[mol.num_nodes] = 0\n",
    "    num_nodes[mol.num_nodes] += 1\n",
    "\n",
    "# Select size which has the most samples in the dataset\n",
    "most_samples = sorted(num_nodes, key=num_nodes.get, reverse=True)[0]\n",
    "\n",
    "# Filter\n",
    "dataset = list(filter(lambda mol: mol.num_nodes == most_samples, dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3aee5b-ef99-4138-b510-7cad2d49ac2f",
   "metadata": {},
   "source": [
    "### Convert atom type to one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "951093f4-8b85-4a78-b4ec-66249653ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out how many types of atoms we have in the dataset\n",
    "num_node_types = 0\n",
    "for mol in dataset:\n",
    "    num_node_types = max(int(mol.x.max()), num_node_types)\n",
    "num_node_types += 1\n",
    "\n",
    "for mol in dataset:\n",
    "    new_x = torch.zeros(mol.num_nodes, num_node_types)\n",
    "    for i, atom_type in enumerate(mol.x):\n",
    "        new_x[i] = torch.eye(num_node_types)[atom_type]\n",
    "    mol.x = new_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ffd1dc-0c0b-4b17-b109-16c2db598be5",
   "metadata": {},
   "source": [
    "### Convert from torch geometric data to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60a5a1c-ed49-4398-a1a7-5b630adc6287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20444/20444 [01:36<00:00, 210.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# An adjacency matrix where adj_ij = 1 if i and j don't have a bond\n",
    "real_connections = torch.stack([to_dense_adj(mol.edge_index)[0] for mol in dataset])\n",
    "\n",
    "# Adjacency matrix for a type specific bonds (each type of bond has its own adjacency matrix)\n",
    "real_type_specific_connections = {edge_type: [] for edge_type in range(1, 3 + 1)}\n",
    "for mol in tqdm(dataset):\n",
    "    for edge_type in range(1, 3 + 1):\n",
    "        try:\n",
    "            real_type_specific_connections[edge_type].append(to_dense_adj(mol.edge_index[:, torch.where(mol.edge_attr == edge_type)[0]], max_num_nodes=mol.num_nodes)[0])\n",
    "        except:\n",
    "            real_type_specific_connections[edge_type].append(torch.zeros(mol.num_nodes, mol.num_nodes))\n",
    "real_type_specific_connections = {\n",
    "    edge_type: torch.stack(real_type_specific_connections[edge_type])\n",
    "    for edge_type in range(1, 1 + 3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838ca326-859e-4189-9cc2-054db24938cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_feats = torch.stack([mol.x for mol in dataset])\n",
    "real_adj = torch.stack([real_connections, *[real_type_specific_connections[edge_type] for edge_type in range(1, 3 + 1)]], dim=-1)\n",
    "real_dataset = TensorDataset(real_adj, real_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50a123-e084-4313-95a8-6d3fc87f8197",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ccb994ec-2a48-4969-8cdc-6499758c68a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DISTRIBUTION_DIM = 64\n",
    "MOL_SIZE = dataset[0].num_nodes\n",
    "NUM_FEATURES = dataset[0].num_node_features\n",
    "NUM_EDGE_TYPES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "67fb5d58-bc03-4455-8292-5ae4c9595057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gaussian distribution with mean=0 and std=1 as prior distribution\n",
    "prior = torch.distributions.MultivariateNormal(torch.zeros(DISTRIBUTION_DIM), torch.eye(DISTRIBUTION_DIM))\n",
    "\n",
    "# Generator\n",
    "generator = Generator(DISTRIBUTION_DIM, MOL_SIZE, NUM_FEATURES, NUM_EDGE_TYPES)\n",
    "\n",
    "# Discriminator\n",
    "discriminator = Discriminator(NUM_FEATURES, NUM_EDGE_TYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5919b819-c9d1-4119-b93d-794e010ed705",
   "metadata": {},
   "source": [
    "### An example - generator receives 10 gaussian samples and generates 10 graphs, discriminator decides whether these 10 samples are real or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9eda491a-4bd4-4bbe-b943-83cbbba8b8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8338],\n",
       "        [0.8289],\n",
       "        [0.8296],\n",
       "        [0.8323],\n",
       "        [0.8387],\n",
       "        [0.8325],\n",
       "        [0.8276],\n",
       "        [0.8383],\n",
       "        [0.8356],\n",
       "        [0.8314]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj, feat = generator(prior.sample((10,)))\n",
    "discriminator(adj, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6e673b71-b1d9-4c2e-ad75-2079221be86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0487e-10, 7.8916e-13, 1.0000e+00, 8.5668e-09],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj[0, 0, 5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243f7d11-514d-45a1-a381-84e289dc8c01",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4fd245d1-de86-447d-a9bc-1333712d1d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Generator loss: 0.479\tDiscriminator loss: 1.110\n",
      "Epoch 1 - Generator loss: 0.608\tDiscriminator loss: 1.018\n",
      "Epoch 2 - Generator loss: 0.673\tDiscriminator loss: 0.915\n",
      "Epoch 3 - Generator loss: 0.626\tDiscriminator loss: 0.878\n",
      "Epoch 4 - Generator loss: 0.626\tDiscriminator loss: 0.767\n",
      "Epoch 5 - Generator loss: 0.460\tDiscriminator loss: 0.963\n",
      "Epoch 6 - Generator loss: 0.676\tDiscriminator loss: 0.742\n",
      "Epoch 7 - Generator loss: 0.674\tDiscriminator loss: 0.992\n",
      "Epoch 8 - Generator loss: 0.501\tDiscriminator loss: 0.814\n",
      "Epoch 9 - Generator loss: 0.311\tDiscriminator loss: 1.109\n",
      "Epoch 10 - Generator loss: 0.340\tDiscriminator loss: 0.783\n",
      "Epoch 11 - Generator loss: 0.358\tDiscriminator loss: 1.017\n",
      "Epoch 12 - Generator loss: 0.369\tDiscriminator loss: 1.010\n",
      "Epoch 13 - Generator loss: 0.417\tDiscriminator loss: 0.760\n",
      "Epoch 14 - Generator loss: 0.430\tDiscriminator loss: 0.979\n",
      "Epoch 15 - Generator loss: 0.435\tDiscriminator loss: 0.723\n",
      "Epoch 16 - Generator loss: 0.472\tDiscriminator loss: 0.904\n",
      "Epoch 17 - Generator loss: 0.495\tDiscriminator loss: 0.912\n",
      "Epoch 18 - Generator loss: 0.438\tDiscriminator loss: 0.682\n",
      "Epoch 19 - Generator loss: 0.356\tDiscriminator loss: 1.022\n",
      "Epoch 20 - Generator loss: 0.320\tDiscriminator loss: 0.987\n",
      "Epoch 21 - Generator loss: 0.328\tDiscriminator loss: 1.060\n",
      "Epoch 22 - Generator loss: 0.284\tDiscriminator loss: 1.049\n",
      "Epoch 23 - Generator loss: 0.257\tDiscriminator loss: 1.018\n",
      "Epoch 24 - Generator loss: 0.263\tDiscriminator loss: 1.013\n",
      "Epoch 25 - Generator loss: 0.249\tDiscriminator loss: 1.052\n",
      "Epoch 26 - Generator loss: 0.234\tDiscriminator loss: 1.059\n",
      "Epoch 27 - Generator loss: 0.218\tDiscriminator loss: 1.038\n",
      "Epoch 28 - Generator loss: 0.207\tDiscriminator loss: 1.046\n",
      "Epoch 29 - Generator loss: 0.194\tDiscriminator loss: 1.021\n",
      "Epoch 30 - Generator loss: 0.189\tDiscriminator loss: 1.055\n",
      "Epoch 31 - Generator loss: 0.175\tDiscriminator loss: 1.004\n",
      "Epoch 32 - Generator loss: 0.175\tDiscriminator loss: 1.016\n",
      "Epoch 33 - Generator loss: 0.171\tDiscriminator loss: 1.010\n",
      "Epoch 34 - Generator loss: 0.169\tDiscriminator loss: 1.040\n",
      "Epoch 35 - Generator loss: 0.191\tDiscriminator loss: 1.037\n",
      "Epoch 36 - Generator loss: 0.143\tDiscriminator loss: 1.006\n",
      "Epoch 37 - Generator loss: 0.142\tDiscriminator loss: 1.034\n",
      "Epoch 38 - Generator loss: 0.135\tDiscriminator loss: 1.034\n",
      "Epoch 39 - Generator loss: 0.127\tDiscriminator loss: 1.023\n",
      "Epoch 40 - Generator loss: 0.122\tDiscriminator loss: 1.013\n",
      "Epoch 41 - Generator loss: 0.120\tDiscriminator loss: 1.007\n",
      "Epoch 42 - Generator loss: 0.119\tDiscriminator loss: 1.006\n",
      "Epoch 43 - Generator loss: 0.119\tDiscriminator loss: 1.000\n",
      "Epoch 44 - Generator loss: 0.119\tDiscriminator loss: 1.034\n",
      "Epoch 45 - Generator loss: 0.113\tDiscriminator loss: 1.021\n",
      "Epoch 46 - Generator loss: 0.109\tDiscriminator loss: 1.019\n",
      "Epoch 47 - Generator loss: 0.106\tDiscriminator loss: 1.010\n",
      "Epoch 48 - Generator loss: 0.104\tDiscriminator loss: 1.032\n",
      "Epoch 49 - Generator loss: 0.098\tDiscriminator loss: 1.008\n",
      "Epoch 50 - Generator loss: 0.097\tDiscriminator loss: 1.000\n",
      "Epoch 51 - Generator loss: 0.097\tDiscriminator loss: 1.009\n",
      "Epoch 52 - Generator loss: 0.096\tDiscriminator loss: 1.007\n",
      "Epoch 53 - Generator loss: 0.095\tDiscriminator loss: 1.005\n",
      "Epoch 54 - Generator loss: 0.094\tDiscriminator loss: 1.022\n",
      "Epoch 55 - Generator loss: 0.090\tDiscriminator loss: 1.002\n",
      "Epoch 56 - Generator loss: 0.090\tDiscriminator loss: 0.996\n",
      "Epoch 57 - Generator loss: 0.091\tDiscriminator loss: 1.007\n",
      "Epoch 58 - Generator loss: 0.091\tDiscriminator loss: 1.004\n",
      "Epoch 59 - Generator loss: 0.091\tDiscriminator loss: 1.019\n",
      "Epoch 60 - Generator loss: 0.087\tDiscriminator loss: 1.017\n",
      "Epoch 61 - Generator loss: 0.084\tDiscriminator loss: 0.996\n",
      "Epoch 62 - Generator loss: 0.086\tDiscriminator loss: 0.818\n",
      "Epoch 63 - Generator loss: 0.104\tDiscriminator loss: 1.015\n",
      "Epoch 64 - Generator loss: 0.102\tDiscriminator loss: 1.008\n",
      "Epoch 65 - Generator loss: 0.101\tDiscriminator loss: 1.017\n",
      "Epoch 66 - Generator loss: 0.099\tDiscriminator loss: 1.010\n",
      "Epoch 67 - Generator loss: 0.099\tDiscriminator loss: 1.017\n",
      "Epoch 68 - Generator loss: 0.097\tDiscriminator loss: 0.998\n",
      "Epoch 69 - Generator loss: 0.098\tDiscriminator loss: 1.006\n",
      "Epoch 70 - Generator loss: 0.098\tDiscriminator loss: 0.996\n",
      "Epoch 71 - Generator loss: 0.099\tDiscriminator loss: 1.021\n",
      "Epoch 72 - Generator loss: 0.097\tDiscriminator loss: 0.998\n",
      "Epoch 73 - Generator loss: 0.098\tDiscriminator loss: 0.999\n",
      "Epoch 74 - Generator loss: 0.099\tDiscriminator loss: 1.002\n",
      "Epoch 75 - Generator loss: 0.099\tDiscriminator loss: 0.997\n",
      "Epoch 76 - Generator loss: 0.100\tDiscriminator loss: 1.003\n",
      "Epoch 77 - Generator loss: 0.100\tDiscriminator loss: 1.010\n",
      "Epoch 78 - Generator loss: 0.100\tDiscriminator loss: 1.003\n",
      "Epoch 79 - Generator loss: 0.100\tDiscriminator loss: 1.006\n",
      "Epoch 80 - Generator loss: 0.099\tDiscriminator loss: 0.994\n",
      "Epoch 81 - Generator loss: 0.101\tDiscriminator loss: 0.998\n",
      "Epoch 82 - Generator loss: 0.102\tDiscriminator loss: 0.996\n",
      "Epoch 83 - Generator loss: 0.104\tDiscriminator loss: 1.004\n",
      "Epoch 84 - Generator loss: 0.104\tDiscriminator loss: 0.993\n",
      "Epoch 85 - Generator loss: 0.106\tDiscriminator loss: 1.001\n",
      "Epoch 86 - Generator loss: 0.108\tDiscriminator loss: 0.991\n",
      "Epoch 87 - Generator loss: 0.110\tDiscriminator loss: 0.986\n",
      "Epoch 88 - Generator loss: 0.114\tDiscriminator loss: 1.004\n",
      "Epoch 89 - Generator loss: 0.115\tDiscriminator loss: 0.994\n",
      "Epoch 90 - Generator loss: 0.117\tDiscriminator loss: 0.984\n",
      "Epoch 91 - Generator loss: 0.122\tDiscriminator loss: 0.989\n",
      "Epoch 92 - Generator loss: 0.126\tDiscriminator loss: 0.982\n",
      "Epoch 93 - Generator loss: 0.136\tDiscriminator loss: 0.985\n",
      "Epoch 94 - Generator loss: 0.136\tDiscriminator loss: 0.997\n",
      "Epoch 95 - Generator loss: 0.139\tDiscriminator loss: 0.992\n",
      "Epoch 96 - Generator loss: 0.142\tDiscriminator loss: 0.978\n",
      "Epoch 97 - Generator loss: 0.150\tDiscriminator loss: 1.016\n",
      "Epoch 98 - Generator loss: 0.147\tDiscriminator loss: 0.991\n",
      "Epoch 99 - Generator loss: 0.150\tDiscriminator loss: 0.989\n"
     ]
    }
   ],
   "source": [
    "generator_optimizer = torch.optim.RMSprop(generator.parameters())\n",
    "discriminator_optimizer = torch.optim.RMSprop(discriminator.parameters())\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "real_dataloader = iter(DataLoader(real_dataset, shuffle=True, batch_size=BATCH_SIZE))\n",
    "\n",
    "for epoch in range(100):\n",
    "    ############ Generator ############\n",
    "    generator.train()\n",
    "    generator_optimizer.zero_grad()\n",
    "    \n",
    "    # Generate fake samples\n",
    "    fake_adj, fake_feat = generator(prior.sample((BATCH_SIZE,)))\n",
    "    \n",
    "    # Pass fake samples to discriminator\n",
    "    out = discriminator(fake_adj, fake_feat)\n",
    "    \n",
    "    # Get the loss\n",
    "    ground_truth = torch.ones(BATCH_SIZE, 1)\n",
    "    generator_loss = torch.nn.functional.l1_loss(out, ground_truth)\n",
    "\n",
    "    # Back propagation\n",
    "    generator_loss.backward()\n",
    "    generator_optimizer.step()\n",
    "\n",
    "    \n",
    "    ############ Discriminator ############\n",
    "    discriminator.train()\n",
    "    discriminator_optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    # Pass real samples to the discriminator\n",
    "    real_adj, real_feat = next(real_dataloader)\n",
    "    out = discriminator(real_adj, real_feat)\n",
    "    # Get the loss\n",
    "    ground_truth = torch.ones(BATCH_SIZE, 1)\n",
    "    discriminator_loss = torch.nn.functional.l1_loss(out, ground_truth)\n",
    "    \n",
    "    \n",
    "    # Pass fake samples to the discriminator\n",
    "    fake_adj, fake_feat = generator(prior.sample((BATCH_SIZE,)))\n",
    "    out = discriminator(fake_adj, fake_feat)\n",
    "    # Get the loss\n",
    "    ground_truth = torch.zeros(BATCH_SIZE, 1)\n",
    "    discriminator_loss += torch.nn.functional.l1_loss(out, ground_truth)\n",
    "    \n",
    "    # Back propagation\n",
    "    discriminator_loss.backward()\n",
    "    discriminator_optimizer.step()\n",
    "    \n",
    "    \n",
    "    print(f'Epoch {epoch} - Generator loss: {float(generator_loss):.3f}\\tDiscriminator loss: {float(discriminator_loss):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MolGenerator:Python",
   "language": "python",
   "name": "conda-env-MolGenerator-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
